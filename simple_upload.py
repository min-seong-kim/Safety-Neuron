#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ëª¨ë¸ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
/home/hail/kms/Safety-Neuron/neuron_enhancement/xxxxxx/Llama3_SafetyEnhanced ì„ Hugging Faceì— ì—…ë¡œë“œ
"""

from transformers import AutoModelForCausalLM, AutoTokenizer
from datetime import datetime

# ì„¤ì •
model_path = "/home/hail/kms/Safety-Neuron/neuron_enhancement/xxxxxx/Llama3_SafetyEnhanced"
hf_username = "kmseong"  # ìì‹ ì˜ ê³„ì •ìœ¼ë¡œ ë³€ê²½

# íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ëª¨ë¸ëª… ìƒì„±
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
repo_name = f"{hf_username}/Llama3_SafetyEnhanced_{timestamp}"

print(f"ëª¨ë¸ ê²½ë¡œ: {model_path}")
print(f"ì—…ë¡œë“œ ëŒ€ìƒ: {repo_name}")
print("-" * 50)

# 1. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
print("\n1ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype="auto",
    device_map="auto"
)
print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

print("2ï¸âƒ£ í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...")
tokenizer = AutoTokenizer.from_pretrained(model_path)
print("âœ“ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")

# 2. Hugging Faceì— ì—…ë¡œë“œ
print(f"\n3ï¸âƒ£ Hugging Faceì— ì—…ë¡œë“œ ì¤‘...")
print(f"   ë¦¬í¬ì§€í† ë¦¬: {repo_name}")

model.push_to_hub(
    repo_id=repo_name,
    private=False,
    commit_message="Safety-Enhanced Llama3 model with frozen safety neurons"
)
print("âœ“ ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ")

tokenizer.push_to_hub(
    repo_id=repo_name,
    commit_message="Tokenizer for Safety-Enhanced Llama3"
)
print("âœ“ í† í¬ë‚˜ì´ì € ì—…ë¡œë“œ ì™„ë£Œ")

print("\n" + "=" * 50)
print("âœ… ì™„ë£Œ!")
print("=" * 50)
print(f"ğŸ“ ëª¨ë¸ URL: https://huggingface.co/{repo_name}")
